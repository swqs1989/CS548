{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, LancasterStemmer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Id  OwnerUserId          CreationDate  Score  \\\n",
      "0  469        147.0  2008-08-02T15:11:16Z     21   \n",
      "1  502        147.0  2008-08-02T17:01:58Z     27   \n",
      "2  535        154.0  2008-08-02T18:43:54Z     40   \n",
      "3  594        116.0  2008-08-03T01:15:08Z     25   \n",
      "4  683        199.0  2008-08-03T13:19:16Z     28   \n",
      "\n",
      "                                               Title  \\\n",
      "0  How can I find the full path to a font from it...   \n",
      "1            Get a preview JPEG of a PDF on Windows?   \n",
      "2  Continuous Integration System for a Python Cod...   \n",
      "3     cx_Oracle: How do I iterate over a result set?   \n",
      "4  Using 'in' to match an attribute of Python obj...   \n",
      "\n",
      "                                                Body  \n",
      "0  <p>I am using the Photoshop's javascript API t...  \n",
      "1  <p>I have a cross-platform (Python) applicatio...  \n",
      "2  <p>I'm starting work on a hobby project with a...  \n",
      "3  <p>There are several ways to iterate over a re...  \n",
      "4  <p>I don't remember whether I was dreaming or ...  \n"
     ]
    }
   ],
   "source": [
    "questions = pd.read_csv('Questions.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607282, 7)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                                            502\n",
       "OwnerUserId                                                   147\n",
       "CreationDate                                 2008-08-02T17:01:58Z\n",
       "Score                                                          27\n",
       "Title                     Get a preview JPEG of a PDF on Windows?\n",
       "Body            <p>I have a cross-platform (Python) applicatio...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222.54704733550474"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[\"Body\"].apply(lambda x: len(x.split(\" \"))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[\"Body\"].apply(lambda x: len(x.split(\" \"))).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31300"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[\"Body\"].apply(lambda x: len(x.split(\" \"))).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"/Users/youqiao/workspace/env/nltk_data\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def cleantags(text):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', text)\n",
    "    return cleantext\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def lemmatize_tokens(tokens, lemmatizer):\n",
    "    lemmatized = []\n",
    "    for item in tokens:\n",
    "        lemmatized.append(lemmatizer.lemmatize(item, pos='v'))\n",
    "    return lemmatized\n",
    "\n",
    "def extractwords(tokens):\n",
    "    new_tokens = []\n",
    "    for word, pos in nltk.pos_tag(tokens):\n",
    "        if pos[:2] == 'NN' or pos[:2] == \"JJ\":\n",
    "            new_tokens.append(word)\n",
    "    return new_tokens\n",
    "\n",
    "def excludestopwords(tokens):\n",
    "    new_tokens = []\n",
    "    for word in tokens:\n",
    "        if word not in stopwords:\n",
    "            new_tokens.append(word)\n",
    "    return new_tokens\n",
    "\n",
    "def tokenize_language(text):\n",
    "    text = cleantags(text)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    no_punctuation = text.translate(translator)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    return tokens\n",
    "\n",
    "def tokenize(text):\n",
    "    text = cleantags(text)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    no_punctuation = text.translate(translator)\n",
    "    #no_punctuation = excludestopwords(no_punctuation)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    \n",
    "#     stems = stem_tokens(tokens, stemmer)\n",
    "#     return stems\n",
    "    lemmatizes = lemmatize_tokens(tokens, lemmatizer)\n",
    "    \n",
    "    # return extractwords(lemmatizes)\n",
    "    return lemmatizes\n",
    "\n",
    "def tokenizewithnostem(text):\n",
    "    text = cleantags(text)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    no_punctuation = text.translate(translator)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    lemmatizes = lemmatize_tokens(tokens, lemmatizer)\n",
    "    return lemmatizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[\"content\"] = questions[\"Title\"] + \" \" + questions[\"Body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How can I find the full path to a font from its display name on a Mac? <p>I am using the Photoshop's javascript API to find the fonts in a given PSD.</p>\\n\\n<p>Given a font name returned by the API, I want to find the actual physical font file that that font name corresponds to on the disc.</p>\\n\\n<p>This is all happening in a python program running on OSX so I guess I'm looking for one of:</p>\\n\\n<ul>\\n<li>Some Photoshop javascript</li>\\n<li>A Python function</li>\\n<li>An OSX API that I can call from python</li>\\n</ul>\\n\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.loc[0,\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607282, 7)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampled_data = questions.sample(n=50000, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 7)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 106)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvector = TfidfVectorizer(tokenizer=tokenize, ngram_range = (1,1), min_df = 0.05, max_df = 0.9, stop_words=stop)\n",
    "# tfidfvector = TfidfVectorizer(tokenizer=tokenize, ngram_range = (1,1), stop_words=stop)\n",
    "text_tfidf = tfidfvector.fit_transform(sampled_data[\"content\"])\n",
    "text_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordbag = tfidfvector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'anyone',\n",
       " 'app',\n",
       " 'application',\n",
       " 'array',\n",
       " 'b',\n",
       " 'base',\n",
       " 'c',\n",
       " 'call',\n",
       " 'cant',\n",
       " 'case',\n",
       " 'change',\n",
       " 'class',\n",
       " 'code',\n",
       " 'command',\n",
       " 'create',\n",
       " 'data',\n",
       " 'def',\n",
       " 'different',\n",
       " 'django',\n",
       " 'doesnt',\n",
       " 'dont',\n",
       " 'edit',\n",
       " 'end',\n",
       " 'error',\n",
       " 'example',\n",
       " 'field',\n",
       " 'file',\n",
       " 'fine',\n",
       " 'first',\n",
       " 'follow',\n",
       " 'function',\n",
       " 'gt',\n",
       " 'help',\n",
       " 'id',\n",
       " 'im',\n",
       " 'import',\n",
       " 'input',\n",
       " 'issue',\n",
       " 'ive',\n",
       " 'key',\n",
       " 'last',\n",
       " 'line',\n",
       " 'list',\n",
       " 'look',\n",
       " 'loop',\n",
       " 'ltmodulegt',\n",
       " 'main',\n",
       " 'many',\n",
       " 'message',\n",
       " 'method',\n",
       " 'model',\n",
       " 'module',\n",
       " 'name',\n",
       " 'new',\n",
       " 'none',\n",
       " 'number',\n",
       " 'numpy',\n",
       " 'object',\n",
       " 'order',\n",
       " 'output',\n",
       " 'page',\n",
       " 'part',\n",
       " 'pass',\n",
       " 'point',\n",
       " 'possible',\n",
       " 'print',\n",
       " 'problem',\n",
       " 'process',\n",
       " 'program',\n",
       " 'python',\n",
       " 'question',\n",
       " 'r',\n",
       " 'recent',\n",
       " 'request',\n",
       " 'result',\n",
       " 'return',\n",
       " 'row',\n",
       " 'run',\n",
       " 'script',\n",
       " 'second',\n",
       " 'server',\n",
       " 'simple',\n",
       " 'solution',\n",
       " 'something',\n",
       " 'start',\n",
       " 'string',\n",
       " 'sure',\n",
       " 'test',\n",
       " 'text',\n",
       " 'thank',\n",
       " 'time',\n",
       " 'traceback',\n",
       " 'true',\n",
       " 'try',\n",
       " 'type',\n",
       " 'url',\n",
       " 'use',\n",
       " 'user',\n",
       " 'value',\n",
       " 'variable',\n",
       " 'version',\n",
       " 'way',\n",
       " 'work',\n",
       " 'wrong',\n",
       " 'x']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_df = text_tfidf.toarray()\n",
    "vectorizedtext = pd.DataFrame(text_df, columns=wordbag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youqiao/env/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for word in wordbag:\n",
    "    vectorizedtext.ix[vectorizedtext[word] == 0, word] = 0\n",
    "    vectorizedtext.ix[vectorizedtext[word] != 0, word] = 1\n",
    "    vectorizedtext[word] = vectorizedtext[word].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizedtext.to_csv(\"stackoverflow_default_f_nn.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arfffile = open(\"stackoverflow_default_f_nn.arff\", \"w\")\n",
    "arfffile.write(\"@relation stackoverflow_default_f_nn.data\\n\")\n",
    "for s in wordbag:\n",
    "    arfffile.write(\"@attribute \" + s + \" {0, 1}\\n\")\n",
    "arfffile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = pd.read_csv('Tags.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsfrequency = tags[\"Tag\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagsfrequency = pd.DataFrame(tagsfrequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a62936438>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEoCAYAAACzVD1FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a469de1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagsfrequency.ix[1:10, ].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_django = tags[tags[\"Tag\"] == \"django\"][\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_django = pd.DataFrame(ids_django)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "django_questions = ids_django.set_index('Id').join(questions.set_index('Id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "django_questions['CreationDate'] = django_questions['CreationDate'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_django_questions = django_questions[django_questions[\"CreationDate\"] > \"2016\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11903, 6)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampled_django_questions = sampled_django_questions.sample(n=5000, random_state=36)\n",
    "sampled_django_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11903, 97)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tfidfvector = TfidfVectorizer(tokenizer=tokenize, ngram_range = (1,3), min_df = 0.1, max_df = 0.9, stop_words=stop)\n",
    "d_text_tfidf = d_tfidfvector.fit_transform(sampled_django_questions[\"content\"])\n",
    "d_text_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_wordbag = d_tfidfvector.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " 'add',\n",
       " 'admin',\n",
       " 'also',\n",
       " 'app',\n",
       " 'call',\n",
       " 'cant',\n",
       " 'change',\n",
       " 'class',\n",
       " 'class meta',\n",
       " 'code',\n",
       " 'could',\n",
       " 'create',\n",
       " 'data',\n",
       " 'database',\n",
       " 'def',\n",
       " 'default',\n",
       " 'django',\n",
       " 'doesnt',\n",
       " 'dont',\n",
       " 'else',\n",
       " 'error',\n",
       " 'example',\n",
       " 'field',\n",
       " 'file',\n",
       " 'find',\n",
       " 'first',\n",
       " 'follow',\n",
       " 'form',\n",
       " 'function',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'gt',\n",
       " 'help',\n",
       " 'however',\n",
       " 'id',\n",
       " 'im',\n",
       " 'import',\n",
       " 'ive',\n",
       " 'know',\n",
       " 'kwargs',\n",
       " 'last',\n",
       " 'like',\n",
       " 'line',\n",
       " 'list',\n",
       " 'look',\n",
       " 'make',\n",
       " 'meta',\n",
       " 'method',\n",
       " 'model',\n",
       " 'model class',\n",
       " 'modelspy',\n",
       " 'name',\n",
       " 'need',\n",
       " 'new',\n",
       " 'none',\n",
       " 'object',\n",
       " 'one',\n",
       " 'page',\n",
       " 'post',\n",
       " 'problem',\n",
       " 'project',\n",
       " 'python',\n",
       " 'question',\n",
       " 'renderrequest',\n",
       " 'request',\n",
       " 'result',\n",
       " 'return',\n",
       " 'return renderrequest',\n",
       " 'run',\n",
       " 'save',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'server',\n",
       " 'set',\n",
       " 'show',\n",
       " 'something',\n",
       " 'template',\n",
       " 'thank',\n",
       " 'time',\n",
       " 'true',\n",
       " 'try',\n",
       " 'type',\n",
       " 'update',\n",
       " 'url',\n",
       " 'use',\n",
       " 'use django',\n",
       " 'user',\n",
       " 'value',\n",
       " 'view',\n",
       " 'viewspy',\n",
       " 'want',\n",
       " 'way',\n",
       " 'work',\n",
       " 'would']"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wordbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_text_df = d_text_tfidf.toarray()\n",
    "d_vectorizedtext = pd.DataFrame(d_text_df, columns=d_wordbag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youqiao/env/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for word in d_wordbag:\n",
    "    d_vectorizedtext.ix[d_vectorizedtext[word] == 0, word] = 0\n",
    "    d_vectorizedtext.ix[d_vectorizedtext[word] != 0, word] = 1\n",
    "    d_vectorizedtext[word] = d_vectorizedtext[word].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vectorizedtext.to_csv(\"stackoverflow_default_django.csv\", header=False, index=False)\n",
    "d_arfffile = open(\"stackoverflow_default_django.arff\", \"w\")\n",
    "d_arfffile.write(\"@relation stackoverflow_default_django.data\\n\")\n",
    "for s in d_wordbag:\n",
    "    d_arfffile.write(\"@attribute \" + s + \" {0, 1}\\n\")\n",
    "d_arfffile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import collections\n",
    "class defaultkeydict(collections.defaultdict):\n",
    "    \"\"\"Like defaultdict, but the default_factory is a function of the key.\n",
    "    >>> d = defaultkeydict(len); d['four']\n",
    "    4\n",
    "    \"\"\"\n",
    "    def __missing__(self, key):\n",
    "        self[key] = result = self.default_factory(key)\n",
    "#         print(self)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class obj():\n",
    "    def __init__(self, s):\n",
    "        self.a = s\n",
    "    \n",
    "    def __add__(self, rhs):\n",
    "        return self.a + rhs.a\n",
    "def obje(name):\n",
    "    return obj(\"456\")\n",
    "M = 123\n",
    "eval(\"M\", defaultkeydict(obje))\n",
    "print(eval(\"M\", defaultkeydict(obje)).a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemset = django_questions[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itemset = pd.DataFrame(itemset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemset[\"content\"] = itemset[\"content\"].apply(lambda x: \",\".join(tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemset.to_csv(\"stackoverflow_default_django_text.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other programming language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "languages = {\"javascript\": 0,\"java\": 1,\n",
    "             \"php\": 2,\"css\": 3,\"ruby\": 4,\n",
    "             \"c\": 5,\"swift\": 6,\"scala\": 7,\n",
    "             \"r\": 8,\"matlab\": 9,\"python\": 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607282, 11)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_tv = TfidfVectorizer(tokenizer=tokenize_language, vocabulary=languages)\n",
    "ex_text = ex_tv.fit_transform(questions[\"content\"])\n",
    "ex_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['javascript',\n",
       " 'java',\n",
       " 'php',\n",
       " 'css',\n",
       " 'ruby',\n",
       " 'c',\n",
       " 'swift',\n",
       " 'scala',\n",
       " 'r',\n",
       " 'matlab',\n",
       " 'python']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_wordbag = ex_tv.get_feature_names()\n",
    "ex_wordbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_text_df = ex_text.toarray()\n",
    "ex_text_df = pd.DataFrame(ex_text_df, columns=ex_wordbag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youqiao/env/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for word in ex_wordbag:\n",
    "    ex_text_df.ix[ex_text_df[word] == 0, word] = 0\n",
    "    ex_text_df.ix[ex_text_df[word] != 0, word] = 1\n",
    "    ex_text_df[word] = ex_text_df[word].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex_text_df[\"itemset\"] = ex_text_df.apply(lambda row: genitemset(row, ex_wordbag), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genitemset(row, wordbags):\n",
    "    itemsets = []\n",
    "    for word in wordbags:\n",
    "        if row[word] == 1:\n",
    "            itemsets.append(word)\n",
    "    return \",\".join(itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_text_df[\"itemset\"].to_csv(\"stackoverflow_language.basket\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_text_df.to_csv(\"stackoverflow_language.csv\", header=False, index=False)\n",
    "ex_arfffile = open(\"stackoverflow_language.arff\", \"w\")\n",
    "ex_arfffile.write(\"@relation stackoverflow_language.data\\n\")\n",
    "for s in ex_wordbag:\n",
    "    ex_arfffile.write(\"@attribute \" + s + \" {0, 1}\\n\")\n",
    "ex_arfffile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting pandas topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_pandas = tags[tags[\"Tag\"] == \"pandas\"][\"Id\"]\n",
    "ids_pandas = pd.DataFrame(ids_pandas)\n",
    "pandas_questions = ids_pandas.set_index('Id').join(questions.set_index('Id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5486226</th>\n",
       "      <td>683866.0</td>\n",
       "      <td>2011-03-30T12:26:50Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Rolling median in python</td>\n",
       "      <td>&lt;p&gt;I have some stock data based on daily close...</td>\n",
       "      <td>Rolling median in python &lt;p&gt;I have some stock ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515021</th>\n",
       "      <td>687739.0</td>\n",
       "      <td>2011-04-01T14:50:44Z</td>\n",
       "      <td>8</td>\n",
       "      <td>Compute a compounded return series in Python</td>\n",
       "      <td>&lt;p&gt;Greetings all, I have two series of data: d...</td>\n",
       "      <td>Compute a compounded return series in Python &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558607</th>\n",
       "      <td>687739.0</td>\n",
       "      <td>2011-04-05T21:13:50Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Sort a pandas DataMatrix in ascending order</td>\n",
       "      <td>&lt;p&gt;The pandas DataFrame object has a &lt;a href=\"...</td>\n",
       "      <td>Sort a pandas DataMatrix in ascending order &lt;p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467832</th>\n",
       "      <td>814005.0</td>\n",
       "      <td>2011-06-24T12:31:45Z</td>\n",
       "      <td>8</td>\n",
       "      <td>How to get the correlation between two timeser...</td>\n",
       "      <td>&lt;p&gt;I have two sets of temperature date, which ...</td>\n",
       "      <td>How to get the correlation between two timeser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577546</th>\n",
       "      <td>510187.0</td>\n",
       "      <td>2011-09-28T01:58:38Z</td>\n",
       "      <td>9</td>\n",
       "      <td>Using pandas, how do I subsample a large DataF...</td>\n",
       "      <td>&lt;p&gt;I am trying to subsample rows of a DataFram...</td>\n",
       "      <td>Using pandas, how do I subsample a large DataF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7776679</th>\n",
       "      <td>601314.0</td>\n",
       "      <td>2011-10-15T08:21:17Z</td>\n",
       "      <td>22</td>\n",
       "      <td>append two data frame with pandas</td>\n",
       "      <td>&lt;p&gt;I try to merge dataframes by rows doing:&lt;/p...</td>\n",
       "      <td>append two data frame with pandas &lt;p&gt;I try to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7813132</th>\n",
       "      <td>601314.0</td>\n",
       "      <td>2011-10-18T20:16:12Z</td>\n",
       "      <td>9</td>\n",
       "      <td>Convert array of string (category) to array of...</td>\n",
       "      <td>&lt;p&gt;I am trying to do something very similar to...</td>\n",
       "      <td>Convert array of string (category) to array of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837722</th>\n",
       "      <td>1005409.0</td>\n",
       "      <td>2011-10-20T14:46:14Z</td>\n",
       "      <td>121</td>\n",
       "      <td>What is the most efficient way to loop through...</td>\n",
       "      <td>&lt;p&gt;I want to perform my own complex operations...</td>\n",
       "      <td>What is the most efficient way to loop through...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8273092</th>\n",
       "      <td>668624.0</td>\n",
       "      <td>2011-11-25T18:39:02Z</td>\n",
       "      <td>1</td>\n",
       "      <td>python: pandas install errors</td>\n",
       "      <td>&lt;p&gt;I have the academic distribution of EPD 7.1...</td>\n",
       "      <td>python: pandas install errors &lt;p&gt;I have the ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8451327</th>\n",
       "      <td>1023631.0</td>\n",
       "      <td>2011-12-09T20:27:24Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Python map() function output into Pandas DataF...</td>\n",
       "      <td>&lt;p&gt;I utilize python's map() function to pass p...</td>\n",
       "      <td>Python map() function output into Pandas DataF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8842114</th>\n",
       "      <td>490288.0</td>\n",
       "      <td>2012-01-12T20:52:41Z</td>\n",
       "      <td>6</td>\n",
       "      <td>How to apply slicing on pandas Series of strings</td>\n",
       "      <td>&lt;p&gt;I'm playing with &lt;a href=\"http://pandas.sou...</td>\n",
       "      <td>How to apply slicing on pandas Series of strin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914992</th>\n",
       "      <td>248237.0</td>\n",
       "      <td>2012-01-18T18:00:16Z</td>\n",
       "      <td>3</td>\n",
       "      <td>indexing several csv files with pandas from re...</td>\n",
       "      <td>&lt;p&gt;I have a list of csv files (&lt;code&gt;\"file1\", ...</td>\n",
       "      <td>indexing several csv files with pandas from re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916302</th>\n",
       "      <td>248237.0</td>\n",
       "      <td>2012-01-18T19:41:27Z</td>\n",
       "      <td>22</td>\n",
       "      <td>selecting across multiple columns with python ...</td>\n",
       "      <td>&lt;p&gt;I have a dataframe df in pandas that was bu...</td>\n",
       "      <td>selecting across multiple columns with python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8957175</th>\n",
       "      <td>1162837.0</td>\n",
       "      <td>2012-01-21T22:12:10Z</td>\n",
       "      <td>1</td>\n",
       "      <td>DataFrame to Panel indexed by nonunique column...</td>\n",
       "      <td>&lt;p&gt;The following code should do what I want bu...</td>\n",
       "      <td>DataFrame to Panel indexed by nonunique column...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8966871</th>\n",
       "      <td>1164240.0</td>\n",
       "      <td>2012-01-23T03:21:00Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Running Python/Numpy/Pandas on older secure co...</td>\n",
       "      <td>&lt;p&gt;I'm trying to run a script at work which us...</td>\n",
       "      <td>Running Python/Numpy/Pandas on older secure co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991709</th>\n",
       "      <td>345660.0</td>\n",
       "      <td>2012-01-24T17:59:53Z</td>\n",
       "      <td>118</td>\n",
       "      <td>Why are pandas merges in python faster than da...</td>\n",
       "      <td>&lt;p&gt;I recently came across the &lt;a href=\"http://...</td>\n",
       "      <td>Why are pandas merges in python faster than da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9189425</th>\n",
       "      <td>81657.0</td>\n",
       "      <td>2012-02-08T07:42:11Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Pandas DataFrame serialization</td>\n",
       "      <td>&lt;p&gt;I'm having trouble writing the entries of a...</td>\n",
       "      <td>Pandas DataFrame serialization &lt;p&gt;I'm having t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339184</th>\n",
       "      <td>1088821.0</td>\n",
       "      <td>2012-02-18T06:26:50Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Python: Pandas, Dataframe, Convert 1column dat...</td>\n",
       "      <td>&lt;p&gt;This is Pandas dataframe\\nI want to convert...</td>\n",
       "      <td>Python: Pandas, Dataframe, Convert 1column dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9421412</th>\n",
       "      <td>963989.0</td>\n",
       "      <td>2012-02-23T21:14:19Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Initializing pandas dataframes with and withou...</td>\n",
       "      <td>&lt;p&gt;If I use the following methodology to const...</td>\n",
       "      <td>Initializing pandas dataframes with and withou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9550867</th>\n",
       "      <td>1026987.0</td>\n",
       "      <td>2012-03-03T23:42:13Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Python Pandas Pivot Table</td>\n",
       "      <td>&lt;p&gt;I am trying to do a pivot table of frequenc...</td>\n",
       "      <td>Python Pandas Pivot Table &lt;p&gt;I am trying to do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556892</th>\n",
       "      <td>963033.0</td>\n",
       "      <td>2012-03-04T16:58:45Z</td>\n",
       "      <td>5</td>\n",
       "      <td>Pandas DataFrame - desired index has duplicate...</td>\n",
       "      <td>&lt;p&gt;This is my first time trying Pandas.  I thi...</td>\n",
       "      <td>Pandas DataFrame - desired index has duplicate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9588331</th>\n",
       "      <td>1252759.0</td>\n",
       "      <td>2012-03-06T17:01:47Z</td>\n",
       "      <td>20</td>\n",
       "      <td>Simple cross-tabulation in pandas</td>\n",
       "      <td>&lt;p&gt;I stumbled across &lt;a href=\"http://pandas.py...</td>\n",
       "      <td>Simple cross-tabulation in pandas &lt;p&gt;I stumble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621362</th>\n",
       "      <td>1257502.0</td>\n",
       "      <td>2012-03-08T16:42:30Z</td>\n",
       "      <td>5</td>\n",
       "      <td>how do I compute a weighted moving average usi...</td>\n",
       "      <td>&lt;p&gt;Using pandas I can compute&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li...</td>\n",
       "      <td>how do I compute a weighted moving average usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9641916</th>\n",
       "      <td>1260307.0</td>\n",
       "      <td>2012-03-09T22:36:52Z</td>\n",
       "      <td>6</td>\n",
       "      <td>Python Pandas: can't find numpy.core.multiarra...</td>\n",
       "      <td>&lt;p&gt;Hi I'm an inexperienced python user trying ...</td>\n",
       "      <td>Python Pandas: can't find numpy.core.multiarra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647656</th>\n",
       "      <td>946197.0</td>\n",
       "      <td>2012-03-10T15:35:26Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Pandas dataframe in mixed mode can't serialize...</td>\n",
       "      <td>&lt;p&gt;In Pandas it seems I can't store a datafram...</td>\n",
       "      <td>Pandas dataframe in mixed mode can't serialize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9652832</th>\n",
       "      <td>914308.0</td>\n",
       "      <td>2012-03-11T06:00:56Z</td>\n",
       "      <td>23</td>\n",
       "      <td>How to I load a tsv file into a Pandas DataFrame?</td>\n",
       "      <td>&lt;p&gt;I'm new to python and pandas.  I'm trying t...</td>\n",
       "      <td>How to I load a tsv file into a Pandas DataFra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695668</th>\n",
       "      <td>1267974.0</td>\n",
       "      <td>2012-03-14T03:50:45Z</td>\n",
       "      <td>6</td>\n",
       "      <td>How to specify dtype when using pandas.read_cs...</td>\n",
       "      <td>&lt;p&gt;I have some text files whose format looks l...</td>\n",
       "      <td>How to specify dtype when using pandas.read_cs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9721429</th>\n",
       "      <td>1610626.0</td>\n",
       "      <td>2012-03-15T14:08:31Z</td>\n",
       "      <td>8</td>\n",
       "      <td>How do I read a fix width format text file in ...</td>\n",
       "      <td>&lt;p&gt;I just got my hands on pandas and am figuri...</td>\n",
       "      <td>How do I read a fix width format text file in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9723000</th>\n",
       "      <td>510187.0</td>\n",
       "      <td>2012-03-15T15:33:47Z</td>\n",
       "      <td>5</td>\n",
       "      <td>How do I tell pandas to parse a particular col...</td>\n",
       "      <td>&lt;p&gt;I have a csv file where one of the columns ...</td>\n",
       "      <td>How do I tell pandas to parse a particular col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758450</th>\n",
       "      <td>939715.0</td>\n",
       "      <td>2012-03-18T12:53:06Z</td>\n",
       "      <td>21</td>\n",
       "      <td>Pandas convert dataframe to array of tuples</td>\n",
       "      <td>&lt;p&gt;I have manipulated some data using pandas a...</td>\n",
       "      <td>Pandas convert dataframe to array of tuples &lt;p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40134313</th>\n",
       "      <td>691816.0</td>\n",
       "      <td>2016-10-19T14:29:09Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Conditionally calculated column for a Pandas D...</td>\n",
       "      <td>&lt;p&gt;I have a calculated column in a Pandas Data...</td>\n",
       "      <td>Conditionally calculated column for a Pandas D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40134453</th>\n",
       "      <td>1534017.0</td>\n",
       "      <td>2016-10-19T14:34:33Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Most efficient way to set value in column base...</td>\n",
       "      <td>&lt;p&gt;I have a dataframe like this:&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;...</td>\n",
       "      <td>Most efficient way to set value in column base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40134637</th>\n",
       "      <td>6899616.0</td>\n",
       "      <td>2016-10-19T14:41:57Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Getting column values from multi index data fr...</td>\n",
       "      <td>&lt;p&gt;I have a multi index data frame shown below...</td>\n",
       "      <td>Getting column values from multi index data fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40134664</th>\n",
       "      <td>6007834.0</td>\n",
       "      <td>2016-10-19T14:43:04Z</td>\n",
       "      <td>5</td>\n",
       "      <td>problems dealing with pandas read csv</td>\n",
       "      <td>&lt;p&gt;I've got a problem with pandas read_csv. I ...</td>\n",
       "      <td>problems dealing with pandas read csv &lt;p&gt;I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40134811</th>\n",
       "      <td>5798899.0</td>\n",
       "      <td>2016-10-19T14:49:33Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Issues with try/except, attempting to convert ...</td>\n",
       "      <td>&lt;p&gt;I made a function to clean up any HTML code...</td>\n",
       "      <td>Issues with try/except, attempting to convert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40135459</th>\n",
       "      <td>3971528.0</td>\n",
       "      <td>2016-10-19T15:15:38Z</td>\n",
       "      <td>5</td>\n",
       "      <td>Reading a text file using Pandas where some ro...</td>\n",
       "      <td>&lt;p&gt;I have a dataset in a textfile that looks l...</td>\n",
       "      <td>Reading a text file using Pandas where some ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40136428</th>\n",
       "      <td>5399268.0</td>\n",
       "      <td>2016-10-19T16:00:50Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Python: How to filter a DataFrame of dates in ...</td>\n",
       "      <td>&lt;p&gt;I have a DataFrame of dates and would like ...</td>\n",
       "      <td>Python: How to filter a DataFrame of dates in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40136496</th>\n",
       "      <td>6564826.0</td>\n",
       "      <td>2016-10-19T16:04:20Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Method like argument in function</td>\n",
       "      <td>&lt;p&gt;I want use method in python / pandas like a...</td>\n",
       "      <td>Method like argument in function &lt;p&gt;I want use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40136651</th>\n",
       "      <td>3956899.0</td>\n",
       "      <td>2016-10-19T16:12:41Z</td>\n",
       "      <td>1</td>\n",
       "      <td>'Stack()' output with all Individual index's f...</td>\n",
       "      <td>&lt;p&gt;I have the following DataFrame:&lt;/p&gt;\\n\\n&lt;pre...</td>\n",
       "      <td>'Stack()' output with all Individual index's f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40137140</th>\n",
       "      <td>6268892.0</td>\n",
       "      <td>2016-10-19T16:41:18Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Apply different estimators on data points depe...</td>\n",
       "      <td>&lt;p&gt;I have a large training set of data points ...</td>\n",
       "      <td>Apply different estimators on data points depe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40137232</th>\n",
       "      <td>3079439.0</td>\n",
       "      <td>2016-10-19T16:46:38Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Exponentional values in Python Pandas</td>\n",
       "      <td>&lt;p&gt;Have a case of quite huge numbers in python...</td>\n",
       "      <td>Exponentional values in Python Pandas &lt;p&gt;Have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40137372</th>\n",
       "      <td>1017373.0</td>\n",
       "      <td>2016-10-19T16:54:51Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Concatinating multiple Data frames of differen...</td>\n",
       "      <td>&lt;p&gt;I have 88 different dataFrame of different ...</td>\n",
       "      <td>Concatinating multiple Data frames of differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40137389</th>\n",
       "      <td>4946726.0</td>\n",
       "      <td>2016-10-19T16:55:59Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Calc value count in few columns of DataFrame (...</td>\n",
       "      <td>&lt;p&gt;I have a dataFrame: &lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code&gt;   i...</td>\n",
       "      <td>Calc value count in few columns of DataFrame (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40138090</th>\n",
       "      <td>2301970.0</td>\n",
       "      <td>2016-10-19T17:38:08Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Work with a row in a pandas dataframe without ...</td>\n",
       "      <td>&lt;p&gt;My data is organized in a dataframe:&lt;/p&gt;\\n\\...</td>\n",
       "      <td>Work with a row in a pandas dataframe without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40138350</th>\n",
       "      <td>3121439.0</td>\n",
       "      <td>2016-10-19T17:51:38Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Search for a combination in dataframe to chang...</td>\n",
       "      <td>&lt;p&gt;I want to replace values in a column if the...</td>\n",
       "      <td>Search for a combination in dataframe to chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40138380</th>\n",
       "      <td>6534180.0</td>\n",
       "      <td>2016-10-19T17:53:07Z</td>\n",
       "      <td>1</td>\n",
       "      <td>'DataFrame' object is not callable</td>\n",
       "      <td>&lt;p&gt;I'm trying to create a heatmap using Python...</td>\n",
       "      <td>'DataFrame' object is not callable &lt;p&gt;I'm tryi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40138486</th>\n",
       "      <td>1620040.0</td>\n",
       "      <td>2016-10-19T17:58:51Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Not able to type in Conda Run terminal</td>\n",
       "      <td>&lt;p&gt;This question could be odd or due to some n...</td>\n",
       "      <td>Not able to type in Conda Run terminal &lt;p&gt;This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40138573</th>\n",
       "      <td>5399268.0</td>\n",
       "      <td>2016-10-19T18:03:58Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Python: How to develop a between_time similar ...</td>\n",
       "      <td>&lt;p&gt;I am stick to pandas 0.9.0 as I'm working u...</td>\n",
       "      <td>Python: How to develop a between_time similar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40139184</th>\n",
       "      <td>5754992.0</td>\n",
       "      <td>2016-10-19T18:39:08Z</td>\n",
       "      <td>2</td>\n",
       "      <td>Keeping 'key' column when using groupby with t...</td>\n",
       "      <td>&lt;p&gt;Finding a normalized dataframe removes the ...</td>\n",
       "      <td>Keeping 'key' column when using groupby with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40139216</th>\n",
       "      <td>160511.0</td>\n",
       "      <td>2016-10-19T18:41:36Z</td>\n",
       "      <td>0</td>\n",
       "      <td>python/pandas/sklearn: getting closest matches...</td>\n",
       "      <td>&lt;p&gt;I have a dataframe and am trying to get the...</td>\n",
       "      <td>python/pandas/sklearn: getting closest matches...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40139405</th>\n",
       "      <td>6306448.0</td>\n",
       "      <td>2016-10-19T18:54:13Z</td>\n",
       "      <td>2</td>\n",
       "      <td>building a dataframe from grouped data in pandas</td>\n",
       "      <td>&lt;p&gt;I have a dataframe that looks like this:&lt;/p...</td>\n",
       "      <td>building a dataframe from grouped data in pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40140813</th>\n",
       "      <td>4863152.0</td>\n",
       "      <td>2016-10-19T20:20:31Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Brunel API not read dataframe?</td>\n",
       "      <td>&lt;p&gt;I use this query in my notbook.&lt;/p&gt;\\n\\n&lt;blo...</td>\n",
       "      <td>Brunel API not read dataframe? &lt;p&gt;I use this q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40140933</th>\n",
       "      <td>7044475.0</td>\n",
       "      <td>2016-10-19T20:27:27Z</td>\n",
       "      <td>3</td>\n",
       "      <td>What do &amp;=, |=, and ~ do in Pandas</td>\n",
       "      <td>&lt;p&gt;I frequently see code like this at work:&lt;/p...</td>\n",
       "      <td>What do &amp;=, |=, and ~ do in Pandas &lt;p&gt;I freque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40141856</th>\n",
       "      <td>512652.0</td>\n",
       "      <td>2016-10-19T21:31:52Z</td>\n",
       "      <td>2</td>\n",
       "      <td>How can I manipulate strings in a slice of a p...</td>\n",
       "      <td>&lt;p&gt;I have a &lt;code&gt;MultiIndex&lt;/code&gt; like this:...</td>\n",
       "      <td>How can I manipulate strings in a slice of a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40141881</th>\n",
       "      <td>2336654.0</td>\n",
       "      <td>2016-10-19T21:34:18Z</td>\n",
       "      <td>4</td>\n",
       "      <td>pandas groupby transform behaving differently ...</td>\n",
       "      <td>&lt;p&gt;consider the &lt;code&gt;df&lt;/code&gt;&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;c...</td>\n",
       "      <td>pandas groupby transform behaving differently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40141895</th>\n",
       "      <td>2201603.0</td>\n",
       "      <td>2016-10-19T21:35:05Z</td>\n",
       "      <td>1</td>\n",
       "      <td>How to do a substring using pandas or numpy</td>\n",
       "      <td>&lt;p&gt;I'm trying to do a substring on data from c...</td>\n",
       "      <td>How to do a substring using pandas or numpy &lt;p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40142024</th>\n",
       "      <td>1290147.0</td>\n",
       "      <td>2016-10-19T21:44:57Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Pandas df to dictionary with values as python ...</td>\n",
       "      <td>&lt;p&gt;I have a pandas df containing 'features' fo...</td>\n",
       "      <td>Pandas df to dictionary with values as python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40142265</th>\n",
       "      <td>3885985.0</td>\n",
       "      <td>2016-10-19T22:02:58Z</td>\n",
       "      <td>0</td>\n",
       "      <td>pandas parallel do not stop</td>\n",
       "      <td>&lt;p&gt;i found a panda groupby solution at &lt;a href...</td>\n",
       "      <td>pandas parallel do not stop &lt;p&gt;i found a panda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40142686</th>\n",
       "      <td>4150912.0</td>\n",
       "      <td>2016-10-19T22:42:47Z</td>\n",
       "      <td>1</td>\n",
       "      <td>converting non-numeric to numeric value using ...</td>\n",
       "      <td>&lt;p&gt;I am a machine learning beginner and wan't ...</td>\n",
       "      <td>converting non-numeric to numeric value using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40142766</th>\n",
       "      <td>4114372.0</td>\n",
       "      <td>2016-10-19T22:50:49Z</td>\n",
       "      <td>0</td>\n",
       "      <td>How to remove elements from a nested json with...</td>\n",
       "      <td>&lt;p&gt;I have the following json:&lt;/p&gt;\\n\\n&lt;p&gt;{&lt;/p&gt;\\...</td>\n",
       "      <td>How to remove elements from a nested json with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26854 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          OwnerUserId          CreationDate  Score  \\\n",
       "Id                                                   \n",
       "5486226      683866.0  2011-03-30T12:26:50Z      4   \n",
       "5515021      687739.0  2011-04-01T14:50:44Z      8   \n",
       "5558607      687739.0  2011-04-05T21:13:50Z      2   \n",
       "6467832      814005.0  2011-06-24T12:31:45Z      8   \n",
       "7577546      510187.0  2011-09-28T01:58:38Z      9   \n",
       "7776679      601314.0  2011-10-15T08:21:17Z     22   \n",
       "7813132      601314.0  2011-10-18T20:16:12Z      9   \n",
       "7837722     1005409.0  2011-10-20T14:46:14Z    121   \n",
       "8273092      668624.0  2011-11-25T18:39:02Z      1   \n",
       "8451327     1023631.0  2011-12-09T20:27:24Z      0   \n",
       "8842114      490288.0  2012-01-12T20:52:41Z      6   \n",
       "8914992      248237.0  2012-01-18T18:00:16Z      3   \n",
       "8916302      248237.0  2012-01-18T19:41:27Z     22   \n",
       "8957175     1162837.0  2012-01-21T22:12:10Z      1   \n",
       "8966871     1164240.0  2012-01-23T03:21:00Z      0   \n",
       "8991709      345660.0  2012-01-24T17:59:53Z    118   \n",
       "9189425       81657.0  2012-02-08T07:42:11Z      1   \n",
       "9339184     1088821.0  2012-02-18T06:26:50Z      2   \n",
       "9421412      963989.0  2012-02-23T21:14:19Z      2   \n",
       "9550867     1026987.0  2012-03-03T23:42:13Z      4   \n",
       "9556892      963033.0  2012-03-04T16:58:45Z      5   \n",
       "9588331     1252759.0  2012-03-06T17:01:47Z     20   \n",
       "9621362     1257502.0  2012-03-08T16:42:30Z      5   \n",
       "9641916     1260307.0  2012-03-09T22:36:52Z      6   \n",
       "9647656      946197.0  2012-03-10T15:35:26Z      2   \n",
       "9652832      914308.0  2012-03-11T06:00:56Z     23   \n",
       "9695668     1267974.0  2012-03-14T03:50:45Z      6   \n",
       "9721429     1610626.0  2012-03-15T14:08:31Z      8   \n",
       "9723000      510187.0  2012-03-15T15:33:47Z      5   \n",
       "9758450      939715.0  2012-03-18T12:53:06Z     21   \n",
       "...               ...                   ...    ...   \n",
       "40134313     691816.0  2016-10-19T14:29:09Z      0   \n",
       "40134453    1534017.0  2016-10-19T14:34:33Z      1   \n",
       "40134637    6899616.0  2016-10-19T14:41:57Z      2   \n",
       "40134664    6007834.0  2016-10-19T14:43:04Z      5   \n",
       "40134811    5798899.0  2016-10-19T14:49:33Z      4   \n",
       "40135459    3971528.0  2016-10-19T15:15:38Z      5   \n",
       "40136428    5399268.0  2016-10-19T16:00:50Z      0   \n",
       "40136496    6564826.0  2016-10-19T16:04:20Z      2   \n",
       "40136651    3956899.0  2016-10-19T16:12:41Z      1   \n",
       "40137140    6268892.0  2016-10-19T16:41:18Z      1   \n",
       "40137232    3079439.0  2016-10-19T16:46:38Z      0   \n",
       "40137372    1017373.0  2016-10-19T16:54:51Z      0   \n",
       "40137389    4946726.0  2016-10-19T16:55:59Z      0   \n",
       "40138090    2301970.0  2016-10-19T17:38:08Z      0   \n",
       "40138350    3121439.0  2016-10-19T17:51:38Z      2   \n",
       "40138380    6534180.0  2016-10-19T17:53:07Z      1   \n",
       "40138486    1620040.0  2016-10-19T17:58:51Z      0   \n",
       "40138573    5399268.0  2016-10-19T18:03:58Z      1   \n",
       "40139184    5754992.0  2016-10-19T18:39:08Z      2   \n",
       "40139216     160511.0  2016-10-19T18:41:36Z      0   \n",
       "40139405    6306448.0  2016-10-19T18:54:13Z      2   \n",
       "40140813    4863152.0  2016-10-19T20:20:31Z      0   \n",
       "40140933    7044475.0  2016-10-19T20:27:27Z      3   \n",
       "40141856     512652.0  2016-10-19T21:31:52Z      2   \n",
       "40141881    2336654.0  2016-10-19T21:34:18Z      4   \n",
       "40141895    2201603.0  2016-10-19T21:35:05Z      1   \n",
       "40142024    1290147.0  2016-10-19T21:44:57Z      1   \n",
       "40142265    3885985.0  2016-10-19T22:02:58Z      0   \n",
       "40142686    4150912.0  2016-10-19T22:42:47Z      1   \n",
       "40142766    4114372.0  2016-10-19T22:50:49Z      0   \n",
       "\n",
       "                                                      Title  \\\n",
       "Id                                                            \n",
       "5486226                            Rolling median in python   \n",
       "5515021        Compute a compounded return series in Python   \n",
       "5558607         Sort a pandas DataMatrix in ascending order   \n",
       "6467832   How to get the correlation between two timeser...   \n",
       "7577546   Using pandas, how do I subsample a large DataF...   \n",
       "7776679                   append two data frame with pandas   \n",
       "7813132   Convert array of string (category) to array of...   \n",
       "7837722   What is the most efficient way to loop through...   \n",
       "8273092                       python: pandas install errors   \n",
       "8451327   Python map() function output into Pandas DataF...   \n",
       "8842114    How to apply slicing on pandas Series of strings   \n",
       "8914992   indexing several csv files with pandas from re...   \n",
       "8916302   selecting across multiple columns with python ...   \n",
       "8957175   DataFrame to Panel indexed by nonunique column...   \n",
       "8966871   Running Python/Numpy/Pandas on older secure co...   \n",
       "8991709   Why are pandas merges in python faster than da...   \n",
       "9189425                      Pandas DataFrame serialization   \n",
       "9339184   Python: Pandas, Dataframe, Convert 1column dat...   \n",
       "9421412   Initializing pandas dataframes with and withou...   \n",
       "9550867                           Python Pandas Pivot Table   \n",
       "9556892   Pandas DataFrame - desired index has duplicate...   \n",
       "9588331                   Simple cross-tabulation in pandas   \n",
       "9621362   how do I compute a weighted moving average usi...   \n",
       "9641916   Python Pandas: can't find numpy.core.multiarra...   \n",
       "9647656   Pandas dataframe in mixed mode can't serialize...   \n",
       "9652832   How to I load a tsv file into a Pandas DataFrame?   \n",
       "9695668   How to specify dtype when using pandas.read_cs...   \n",
       "9721429   How do I read a fix width format text file in ...   \n",
       "9723000   How do I tell pandas to parse a particular col...   \n",
       "9758450         Pandas convert dataframe to array of tuples   \n",
       "...                                                     ...   \n",
       "40134313  Conditionally calculated column for a Pandas D...   \n",
       "40134453  Most efficient way to set value in column base...   \n",
       "40134637  Getting column values from multi index data fr...   \n",
       "40134664              problems dealing with pandas read csv   \n",
       "40134811  Issues with try/except, attempting to convert ...   \n",
       "40135459  Reading a text file using Pandas where some ro...   \n",
       "40136428  Python: How to filter a DataFrame of dates in ...   \n",
       "40136496                   Method like argument in function   \n",
       "40136651  'Stack()' output with all Individual index's f...   \n",
       "40137140  Apply different estimators on data points depe...   \n",
       "40137232              Exponentional values in Python Pandas   \n",
       "40137372  Concatinating multiple Data frames of differen...   \n",
       "40137389  Calc value count in few columns of DataFrame (...   \n",
       "40138090  Work with a row in a pandas dataframe without ...   \n",
       "40138350  Search for a combination in dataframe to chang...   \n",
       "40138380                 'DataFrame' object is not callable   \n",
       "40138486             Not able to type in Conda Run terminal   \n",
       "40138573  Python: How to develop a between_time similar ...   \n",
       "40139184  Keeping 'key' column when using groupby with t...   \n",
       "40139216  python/pandas/sklearn: getting closest matches...   \n",
       "40139405   building a dataframe from grouped data in pandas   \n",
       "40140813                     Brunel API not read dataframe?   \n",
       "40140933                 What do &=, |=, and ~ do in Pandas   \n",
       "40141856  How can I manipulate strings in a slice of a p...   \n",
       "40141881  pandas groupby transform behaving differently ...   \n",
       "40141895        How to do a substring using pandas or numpy   \n",
       "40142024  Pandas df to dictionary with values as python ...   \n",
       "40142265                        pandas parallel do not stop   \n",
       "40142686  converting non-numeric to numeric value using ...   \n",
       "40142766  How to remove elements from a nested json with...   \n",
       "\n",
       "                                                       Body  \\\n",
       "Id                                                            \n",
       "5486226   <p>I have some stock data based on daily close...   \n",
       "5515021   <p>Greetings all, I have two series of data: d...   \n",
       "5558607   <p>The pandas DataFrame object has a <a href=\"...   \n",
       "6467832   <p>I have two sets of temperature date, which ...   \n",
       "7577546   <p>I am trying to subsample rows of a DataFram...   \n",
       "7776679   <p>I try to merge dataframes by rows doing:</p...   \n",
       "7813132   <p>I am trying to do something very similar to...   \n",
       "7837722   <p>I want to perform my own complex operations...   \n",
       "8273092   <p>I have the academic distribution of EPD 7.1...   \n",
       "8451327   <p>I utilize python's map() function to pass p...   \n",
       "8842114   <p>I'm playing with <a href=\"http://pandas.sou...   \n",
       "8914992   <p>I have a list of csv files (<code>\"file1\", ...   \n",
       "8916302   <p>I have a dataframe df in pandas that was bu...   \n",
       "8957175   <p>The following code should do what I want bu...   \n",
       "8966871   <p>I'm trying to run a script at work which us...   \n",
       "8991709   <p>I recently came across the <a href=\"http://...   \n",
       "9189425   <p>I'm having trouble writing the entries of a...   \n",
       "9339184   <p>This is Pandas dataframe\\nI want to convert...   \n",
       "9421412   <p>If I use the following methodology to const...   \n",
       "9550867   <p>I am trying to do a pivot table of frequenc...   \n",
       "9556892   <p>This is my first time trying Pandas.  I thi...   \n",
       "9588331   <p>I stumbled across <a href=\"http://pandas.py...   \n",
       "9621362   <p>Using pandas I can compute</p>\\n\\n<ul>\\n<li...   \n",
       "9641916   <p>Hi I'm an inexperienced python user trying ...   \n",
       "9647656   <p>In Pandas it seems I can't store a datafram...   \n",
       "9652832   <p>I'm new to python and pandas.  I'm trying t...   \n",
       "9695668   <p>I have some text files whose format looks l...   \n",
       "9721429   <p>I just got my hands on pandas and am figuri...   \n",
       "9723000   <p>I have a csv file where one of the columns ...   \n",
       "9758450   <p>I have manipulated some data using pandas a...   \n",
       "...                                                     ...   \n",
       "40134313  <p>I have a calculated column in a Pandas Data...   \n",
       "40134453  <p>I have a dataframe like this:</p>\\n\\n<pre><...   \n",
       "40134637  <p>I have a multi index data frame shown below...   \n",
       "40134664  <p>I've got a problem with pandas read_csv. I ...   \n",
       "40134811  <p>I made a function to clean up any HTML code...   \n",
       "40135459  <p>I have a dataset in a textfile that looks l...   \n",
       "40136428  <p>I have a DataFrame of dates and would like ...   \n",
       "40136496  <p>I want use method in python / pandas like a...   \n",
       "40136651  <p>I have the following DataFrame:</p>\\n\\n<pre...   \n",
       "40137140  <p>I have a large training set of data points ...   \n",
       "40137232  <p>Have a case of quite huge numbers in python...   \n",
       "40137372  <p>I have 88 different dataFrame of different ...   \n",
       "40137389  <p>I have a dataFrame: </p>\\n\\n<pre><code>   i...   \n",
       "40138090  <p>My data is organized in a dataframe:</p>\\n\\...   \n",
       "40138350  <p>I want to replace values in a column if the...   \n",
       "40138380  <p>I'm trying to create a heatmap using Python...   \n",
       "40138486  <p>This question could be odd or due to some n...   \n",
       "40138573  <p>I am stick to pandas 0.9.0 as I'm working u...   \n",
       "40139184  <p>Finding a normalized dataframe removes the ...   \n",
       "40139216  <p>I have a dataframe and am trying to get the...   \n",
       "40139405  <p>I have a dataframe that looks like this:</p...   \n",
       "40140813  <p>I use this query in my notbook.</p>\\n\\n<blo...   \n",
       "40140933  <p>I frequently see code like this at work:</p...   \n",
       "40141856  <p>I have a <code>MultiIndex</code> like this:...   \n",
       "40141881  <p>consider the <code>df</code></p>\\n\\n<pre><c...   \n",
       "40141895  <p>I'm trying to do a substring on data from c...   \n",
       "40142024  <p>I have a pandas df containing 'features' fo...   \n",
       "40142265  <p>i found a panda groupby solution at <a href...   \n",
       "40142686  <p>I am a machine learning beginner and wan't ...   \n",
       "40142766  <p>I have the following json:</p>\\n\\n<p>{</p>\\...   \n",
       "\n",
       "                                                    content  \n",
       "Id                                                           \n",
       "5486226   Rolling median in python <p>I have some stock ...  \n",
       "5515021   Compute a compounded return series in Python <...  \n",
       "5558607   Sort a pandas DataMatrix in ascending order <p...  \n",
       "6467832   How to get the correlation between two timeser...  \n",
       "7577546   Using pandas, how do I subsample a large DataF...  \n",
       "7776679   append two data frame with pandas <p>I try to ...  \n",
       "7813132   Convert array of string (category) to array of...  \n",
       "7837722   What is the most efficient way to loop through...  \n",
       "8273092   python: pandas install errors <p>I have the ac...  \n",
       "8451327   Python map() function output into Pandas DataF...  \n",
       "8842114   How to apply slicing on pandas Series of strin...  \n",
       "8914992   indexing several csv files with pandas from re...  \n",
       "8916302   selecting across multiple columns with python ...  \n",
       "8957175   DataFrame to Panel indexed by nonunique column...  \n",
       "8966871   Running Python/Numpy/Pandas on older secure co...  \n",
       "8991709   Why are pandas merges in python faster than da...  \n",
       "9189425   Pandas DataFrame serialization <p>I'm having t...  \n",
       "9339184   Python: Pandas, Dataframe, Convert 1column dat...  \n",
       "9421412   Initializing pandas dataframes with and withou...  \n",
       "9550867   Python Pandas Pivot Table <p>I am trying to do...  \n",
       "9556892   Pandas DataFrame - desired index has duplicate...  \n",
       "9588331   Simple cross-tabulation in pandas <p>I stumble...  \n",
       "9621362   how do I compute a weighted moving average usi...  \n",
       "9641916   Python Pandas: can't find numpy.core.multiarra...  \n",
       "9647656   Pandas dataframe in mixed mode can't serialize...  \n",
       "9652832   How to I load a tsv file into a Pandas DataFra...  \n",
       "9695668   How to specify dtype when using pandas.read_cs...  \n",
       "9721429   How do I read a fix width format text file in ...  \n",
       "9723000   How do I tell pandas to parse a particular col...  \n",
       "9758450   Pandas convert dataframe to array of tuples <p...  \n",
       "...                                                     ...  \n",
       "40134313  Conditionally calculated column for a Pandas D...  \n",
       "40134453  Most efficient way to set value in column base...  \n",
       "40134637  Getting column values from multi index data fr...  \n",
       "40134664  problems dealing with pandas read csv <p>I've ...  \n",
       "40134811  Issues with try/except, attempting to convert ...  \n",
       "40135459  Reading a text file using Pandas where some ro...  \n",
       "40136428  Python: How to filter a DataFrame of dates in ...  \n",
       "40136496  Method like argument in function <p>I want use...  \n",
       "40136651  'Stack()' output with all Individual index's f...  \n",
       "40137140  Apply different estimators on data points depe...  \n",
       "40137232  Exponentional values in Python Pandas <p>Have ...  \n",
       "40137372  Concatinating multiple Data frames of differen...  \n",
       "40137389  Calc value count in few columns of DataFrame (...  \n",
       "40138090  Work with a row in a pandas dataframe without ...  \n",
       "40138350  Search for a combination in dataframe to chang...  \n",
       "40138380  'DataFrame' object is not callable <p>I'm tryi...  \n",
       "40138486  Not able to type in Conda Run terminal <p>This...  \n",
       "40138573  Python: How to develop a between_time similar ...  \n",
       "40139184  Keeping 'key' column when using groupby with t...  \n",
       "40139216  python/pandas/sklearn: getting closest matches...  \n",
       "40139405  building a dataframe from grouped data in pand...  \n",
       "40140813  Brunel API not read dataframe? <p>I use this q...  \n",
       "40140933  What do &=, |=, and ~ do in Pandas <p>I freque...  \n",
       "40141856  How can I manipulate strings in a slice of a p...  \n",
       "40141881  pandas groupby transform behaving differently ...  \n",
       "40141895  How to do a substring using pandas or numpy <p...  \n",
       "40142024  Pandas df to dictionary with values as python ...  \n",
       "40142265  pandas parallel do not stop <p>i found a panda...  \n",
       "40142686  converting non-numeric to numeric value using ...  \n",
       "40142766  How to remove elements from a nested json with...  \n",
       "\n",
       "[26854 rows x 6 columns]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26854, 103)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tfidfvector = TfidfVectorizer(tokenizer=tokenizewithnostem, ngram_range = (1,3), min_df = 0.1, max_df = 0.9, stop_words=stop)\n",
    "pd_text_tfidf = pd_tfidfvector.fit_transform(pandas_questions[\"content\"])\n",
    "pd_text_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '0 1',\n",
       " '1',\n",
       " '1 1',\n",
       " '1 2',\n",
       " '10',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'add',\n",
       " 'also',\n",
       " 'b',\n",
       " 'base',\n",
       " 'c',\n",
       " 'call',\n",
       " 'code',\n",
       " 'column',\n",
       " 'columns',\n",
       " 'contain',\n",
       " 'convert',\n",
       " 'could',\n",
       " 'create',\n",
       " 'csv',\n",
       " 'data',\n",
       " 'data frame',\n",
       " 'dataframe',\n",
       " 'date',\n",
       " 'def',\n",
       " 'df',\n",
       " 'different',\n",
       " 'error',\n",
       " 'example',\n",
       " 'file',\n",
       " 'find',\n",
       " 'first',\n",
       " 'follow',\n",
       " 'frame',\n",
       " 'function',\n",
       " 'get',\n",
       " 'give',\n",
       " 'group',\n",
       " 'help',\n",
       " 'however',\n",
       " 'id',\n",
       " 'im',\n",
       " 'import',\n",
       " 'import pandas',\n",
       " 'import pandas pd',\n",
       " 'index',\n",
       " 'ive',\n",
       " 'know',\n",
       " 'last',\n",
       " 'like',\n",
       " 'line',\n",
       " 'list',\n",
       " 'look',\n",
       " 'look like',\n",
       " 'make',\n",
       " 'name',\n",
       " 'nan',\n",
       " 'need',\n",
       " 'new',\n",
       " 'number',\n",
       " 'numpy',\n",
       " 'object',\n",
       " 'one',\n",
       " 'output',\n",
       " 'pandas',\n",
       " 'pandas dataframe',\n",
       " 'pandas pd',\n",
       " 'pd',\n",
       " 'print',\n",
       " 'problem',\n",
       " 'python',\n",
       " 'question',\n",
       " 'read',\n",
       " 'result',\n",
       " 'return',\n",
       " 'row',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'series',\n",
       " 'set',\n",
       " 'something',\n",
       " 'string',\n",
       " 'thank',\n",
       " 'time',\n",
       " 'try',\n",
       " 'two',\n",
       " 'use',\n",
       " 'use pandas',\n",
       " 'value',\n",
       " 'want',\n",
       " 'way',\n",
       " 'work',\n",
       " 'would',\n",
       " 'would like',\n",
       " 'x']"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_wordbag = pd_tfidfvector.get_feature_names()\n",
    "pd_wordbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makearff(tag, filename):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youqiao/env/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "pd_text_df = pd_text_tfidf.toarray()\n",
    "pd_text_df = pd.DataFrame(pd_text_df, columns=pd_wordbag)\n",
    "for word in pd_wordbag:\n",
    "    pd_text_df.ix[pd_text_df[word] == 0, word] = 0\n",
    "    pd_text_df.ix[pd_text_df[word] != 0, word] = 1\n",
    "    pd_text_df[word] = pd_text_df[word].astype(int)\n",
    "\n",
    "pd_text_df.to_csv(\"stackoverflow_pandas.csv\", header=False, index=False)\n",
    "pd_arfffile = open(\"stackoverflow_pandas.arff\", \"w\")\n",
    "pd_arfffile.write(\"@relation stackoverflow_pandas.data\\n\")\n",
    "for s in pd_wordbag:\n",
    "    pd_arfffile.write(\"@attribute \" + s + \" {0, 1}\\n\")\n",
    "pd_arfffile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1 = open(\"123.txt\", \"w\")\n",
    "file1.write(\"123\\n\")\n",
    "file1.write(\"456\\n\")\n",
    "file1.write(\"789\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ash_jsd'"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
